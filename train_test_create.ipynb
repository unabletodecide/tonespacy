{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f41c6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47ed0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('order_phrases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0116b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spoken_text</th>\n",
       "      <th>split</th>\n",
       "      <th>prod_start_char</th>\n",
       "      <th>prod_end_char</th>\n",
       "      <th>qty</th>\n",
       "      <th>qty_char</th>\n",
       "      <th>c_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i want 1 cappuccino from CCD</td>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>cappuccino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I want 2 flat white from CCD</td>\n",
       "      <td>train</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>flat white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dark frappe one</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>one</td>\n",
       "      <td>13</td>\n",
       "      <td>dark frappe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Give me espresso 3</td>\n",
       "      <td>train</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>espresso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My order is classic filter coffee 45</td>\n",
       "      <td>train</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>classic filter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            spoken_text  split  prod_start_char  \\\n",
       "0          i want 1 cappuccino from CCD  train               10   \n",
       "1          I want 2 flat white from CCD  train               10   \n",
       "2                       dark frappe one  train                1   \n",
       "3                    Give me espresso 3  train                9   \n",
       "4  My order is classic filter coffee 45  train               13   \n",
       "\n",
       "   prod_end_char  qty  qty_char          c_name  \n",
       "0             19    1         8      cappuccino  \n",
       "1             19    2         8      flat white  \n",
       "2             11  one        13     dark frappe  \n",
       "3             16    3        18        espresso  \n",
       "4             26   45        35  classic filter  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbc442f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pdf[pdf[\"split\"]=='train']\n",
    "test_data = pdf[pdf[\"split\"]=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bca2e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.iloc[0]['prod_start_char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0564218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = train_data['spoken_text'].to_list()\n",
    "all_unseen_text = test_data['spoken_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63d68e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want 1 cappuccino from CCD'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91616cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = []\n",
    "TEST_DATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e802f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i want 1 cappuccino from CCD',\n",
       "  {'entities': [(10, 19, 'PRODUCT'), (8, 8, 'NUMBER')]}),\n",
       " ('I want 2 flat white from CCD',\n",
       "  {'entities': [(10, 19, 'PRODUCT'), (8, 8, 'NUMBER')]}),\n",
       " ('dark frappe one', {'entities': [(1, 11, 'PRODUCT'), (13, 15, 'NUMBER')]}),\n",
       " ('Give me espresso 3',\n",
       "  {'entities': [(9, 16, 'PRODUCT'), (18, 18, 'NUMBER')]}),\n",
       " ('My order is classic filter coffee 45',\n",
       "  {'entities': [(13, 26, 'PRODUCT'), (35, 36, 'NUMBER')]}),\n",
       " ('Bring macchiato 9 large',\n",
       "  {'entities': [(7, 15, 'PRODUCT'), (17, 17, 'NUMBER')]}),\n",
       " ('cafe americano two please',\n",
       "  {'entities': [(1, 14, 'PRODUCT'), (16, 18, 'NUMBER')]}),\n",
       " ('cafe mocha 8 for me',\n",
       "  {'entities': [(1, 10, 'PRODUCT'), (12, 12, 'NUMBER')]}),\n",
       " ('aztec coffee 200 cups for me',\n",
       "  {'entities': [(1, 5, 'PRODUCT'), (14, 16, 'NUMBER')]}),\n",
       " ('1 large ethiopian coffee for me',\n",
       "  {'entities': [(11, 19, 'PRODUCT'), (1, 1, 'NUMBER')]}),\n",
       " ('give me 2 cafe latte',\n",
       "  {'entities': [(11, 20, 'PRODUCT'), (9, 9, 'NUMBER')]}),\n",
       " ('make 11 coconut milk latte for me',\n",
       "  {'entities': [(9, 26, 'PRODUCT'), (6, 7, 'NUMBER')]}),\n",
       " ('do you have 7 toffee cappuccino?',\n",
       "  {'entities': [(15, 31, 'PRODUCT'), (13, 13, 'NUMBER')]}),\n",
       " ('I would like 23 vanilla cappuccino',\n",
       "  {'entities': [(17, 34, 'PRODUCT'), (14, 15, 'NUMBER')]}),\n",
       " ('17 vanilla latte for me please',\n",
       "  {'entities': [(4, 16, 'PRODUCT'), (1, 2, 'NUMBER')]}),\n",
       " ('get 54 toffee latte right now',\n",
       "  {'entities': [(8, 19, 'PRODUCT'), (5, 6, 'NUMBER')]})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(all_text)):\n",
    "    data=[0]*2\n",
    "    data[0] = all_text[i]\n",
    "    ent_dict = {}\n",
    "    dict_data_1 = [train_data.iloc[i]['prod_start_char'], train_data.iloc[i]['prod_end_char'], \"PRODUCT\"]\n",
    "    dict_data_2 = [train_data.iloc[i]['qty_char'], (int(train_data.iloc[i]['qty_char'])+(len(str(train_data.iloc[i]['qty']))-1)), \"NUMBER\"]\n",
    "    ent_dict[\"entities\"] = [tuple(dict_data_1), tuple(dict_data_2)]\n",
    "    data[1] = ent_dict\n",
    "    TRAIN_DATA.append(tuple(data))\n",
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9f57f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('100 aztec please', {'entities': [(5, 9, 'PRODUCT'), (1, 3, 'NUMBER')]}),\n",
       " ('30 mocha for me', {'entities': [(4, 8, 'PRODUCT'), (1, 2, 'NUMBER')]}),\n",
       " ('get me three frappes',\n",
       "  {'entities': [(14, 19, 'PRODUCT'), (8, 12, 'NUMBER')]}),\n",
       " ('Can I have four espresso please?',\n",
       "  {'entities': [(17, 24, 'PRODUCT'), (12, 15, 'NUMBER')]}),\n",
       " ('5 large cappuccino for me',\n",
       "  {'entities': [(9, 18, 'PRODUCT'), (1, 1, 'NUMBER')]}),\n",
       " ('My order is 10 dark frappe',\n",
       "  {'entities': [(16, 26, 'PRODUCT'), (13, 14, 'NUMBER')]}),\n",
       " ('Get me 22 coconut milk latte',\n",
       "  {'entities': [(11, 28, 'PRODUCT'), (8, 9, 'NUMBER')]})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(all_unseen_text)):\n",
    "    data=[0]*2\n",
    "    data[0] = all_unseen_text[i]\n",
    "    ent_dict = {}\n",
    "    dict_data_1 = [test_data.iloc[i]['prod_start_char'], test_data.iloc[i]['prod_end_char'], \"PRODUCT\"]\n",
    "    dict_data_2 = [test_data.iloc[i]['qty_char'], int(test_data.iloc[i]['qty_char'])+(len(str(test_data.iloc[i]['qty']).strip())-1), \"NUMBER\"]\n",
    "    ent_dict[\"entities\"] = [tuple(dict_data_1), tuple(dict_data_2)]\n",
    "    data[1] = ent_dict\n",
    "    TEST_DATA.append(tuple(data))\n",
    "TEST_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f5cf1",
   "metadata": {},
   "source": [
    "### Spacy 2 to 3 conversion of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b179dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c75ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22041d54",
   "metadata": {},
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf7c6c",
   "metadata": {},
   "source": [
    "ner=nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d87778",
   "metadata": {},
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "  for ent in annotations.get(\"entities\"):\n",
    "    ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b713ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 454.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want 1 cappuccino from CCD 10 19 PRODUCT\n",
      "[cappuccino]\n",
      "i want 1 cappuccino from CCD 8 8 NUMBER\n",
      "[cappuccino, ]\n",
      "I want 2 flat white from CCD 10 19 PRODUCT\n",
      "[flat white]\n",
      "I want 2 flat white from CCD 8 8 NUMBER\n",
      "[flat white, ]\n",
      "dark frappe one 1 11 PRODUCT\n",
      "[dark frappe]\n",
      "dark frappe one 13 15 NUMBER\n",
      "[dark frappe, one]\n",
      "Give me espresso 3 9 16 PRODUCT\n",
      "[espresso]\n",
      "Give me espresso 3 18 18 NUMBER\n",
      "Skipping entity NUMBER\n",
      "My order is classic filter coffee 45 13 26 PRODUCT\n",
      "[classic filter]\n",
      "My order is classic filter coffee 45 35 36 NUMBER\n",
      "[classic filter, 45]\n",
      "Bring macchiato 9 large 7 15 PRODUCT\n",
      "[macchiato]\n",
      "Bring macchiato 9 large 17 17 NUMBER\n",
      "[macchiato, ]\n",
      "cafe americano two please 1 14 PRODUCT\n",
      "[cafe americano]\n",
      "cafe americano two please 16 18 NUMBER\n",
      "[cafe americano, two]\n",
      "cafe mocha 8 for me 1 10 PRODUCT\n",
      "[cafe mocha]\n",
      "cafe mocha 8 for me 12 12 NUMBER\n",
      "[cafe mocha, ]\n",
      "aztec coffee 200 cups for me 1 5 PRODUCT\n",
      "[aztec]\n",
      "aztec coffee 200 cups for me 14 16 NUMBER\n",
      "[aztec, 200]\n",
      "1 large ethiopian coffee for me 11 19 PRODUCT\n",
      "[ethiopian coffee]\n",
      "1 large ethiopian coffee for me 1 1 NUMBER\n",
      "[ethiopian coffee, ]\n",
      "give me 2 cafe latte 11 20 PRODUCT\n",
      "[cafe latte]\n",
      "give me 2 cafe latte 9 9 NUMBER\n",
      "[cafe latte, ]\n",
      "make 11 coconut milk latte for me 9 26 PRODUCT\n",
      "[coconut milk latte]\n",
      "make 11 coconut milk latte for me 6 7 NUMBER\n",
      "[coconut milk latte, 11]\n",
      "do you have 7 toffee cappuccino? 15 31 PRODUCT\n",
      "[toffee cappuccino]\n",
      "do you have 7 toffee cappuccino? 13 13 NUMBER\n",
      "[toffee cappuccino, ]\n",
      "I would like 23 vanilla cappuccino 17 34 PRODUCT\n",
      "[vanilla cappuccino]\n",
      "I would like 23 vanilla cappuccino 14 15 NUMBER\n",
      "[vanilla cappuccino, 23]\n",
      "17 vanilla latte for me please 4 16 PRODUCT\n",
      "[vanilla latte]\n",
      "17 vanilla latte for me please 1 2 NUMBER\n",
      "[vanilla latte, 17]\n",
      "get 54 toffee latte right now 8 19 PRODUCT\n",
      "[toffee latte]\n",
      "get 54 toffee latte right now 5 6 NUMBER\n",
      "[toffee latte, 54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "db = DocBin() # create a DocBin object\n",
    "\n",
    "for text, annot in tqdm(TRAIN_DATA): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        print (doc, start, end, label)\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity \"+label)\n",
    "        else:\n",
    "            ents.append(span)\n",
    "            print(ents)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./train.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c49051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 621.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# load a new spacy model\n",
    "db = DocBin() # create a DocBin object\n",
    "\n",
    "for text, annot in tqdm(TEST_DATA): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity \"+label)\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"./test.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0768fea",
   "metadata": {},
   "source": [
    "## To train, run:\n",
    "#### python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./test.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d945aad6",
   "metadata": {},
   "source": [
    "# Only after you run the above command, check below output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2252fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1 = spacy.load(Path(os.getcwd()+\"/output/model-best\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35c551e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">i want \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    11\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cappuccino\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    22\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    flat white\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " from CCD</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp1(\"i want 11 cappuccino and 22 flat white from CCD\") # input sample text\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True) # display in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52bc68e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I would like \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    23\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUMBER</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    machhiato\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp1(\"I would like 23 machhiato\")\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab90e62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5910b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527b50d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7034a745",
   "metadata": {},
   "source": [
    "## Below are some experimental tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17431571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.tok2vec.Tok2Vec at 0x7f0aa5011680>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\", exclude=[\"ner\", \"tok2vec\"])\n",
    "nlp.add_pipe(\"ner\", source=nlp1)\n",
    "nlp.add_pipe(\"tok2vec\", source=nlp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e88aa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner=nlp.get_pipe(\"ner\")\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4edb900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ents': ['NUMBER', 'PRODUCT'],\n",
       " 'colors': {'NUMBER': '#ffe119', 'PRODUCT': '#3cb44b'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_entity_options():\n",
    "    col_dict = {}\n",
    "    list_colours = ['#ffe119', '#3cb44b']\n",
    "    for label, colour in zip(nlp.pipe_labels['ner'], list_colours):\n",
    "        col_dict[label] = colour\n",
    "    options = {\"ents\": nlp.pipe_labels['ner'], \"colors\": col_dict}\n",
    "    return options\n",
    "get_entity_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd2ce484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities []\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I want 6 flat white\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129853a2",
   "metadata": {},
   "source": [
    "## Somehow build a dependency graph and link the prodcut to its number, you may also check nearest node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9653ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [token for token in doc if token.like_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb00a538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I nsubj want ADP []\n",
      "want nsubj 6 ADP [I]\n",
      "6 nsubj flat ADP [want]\n",
      "flat ROOT flat ADP [6]\n",
      "white ROOT white ADP []\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53baef1",
   "metadata": {},
   "source": [
    "pipes_to_disable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9c523b",
   "metadata": {},
   "source": [
    "nlang = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9dd78f",
   "metadata": {},
   "source": [
    "ner=nlang.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ed756",
   "metadata": {},
   "source": [
    "pipes_disable_except = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "pipes_to_disable = [pipe for pipe in nlang.pipe_names if pipe not in pipes_disable_except]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c70a0",
   "metadata": {},
   "source": [
    "with nlang.disable_pipes(*pipes_to_disable):\n",
    "    for i in range(40):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "<!-- #         batches = minibatch(TRAIN_DATA, size=compounding(2.0, 32.0, 1.001))\n",
    "#         for batch in batches: -->\n",
    "        for batch in minibatch(TRAIN_DATA, size=2):\n",
    "            for text, annotations in batch:\n",
    "<!-- #                 texts, annotations = zip(*batch) -->\n",
    "                doc = nlang.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlang.update([example],\n",
    "                            drop=0.5,  # drop half\n",
    "                            losses=losses,)\n",
    "                print(\"Loss: \", losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2c6c7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc026b6b",
   "metadata": {},
   "source": [
    "ner=nlp.get_pipe(\"ner\")\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        print(ent[2])\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c05a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b08a82e",
   "metadata": {},
   "source": [
    "examples = []\n",
    "for text, annots in TRAIN_DATA:\n",
    "    spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), annots[\"entities\"])\n",
    "    examples.append(Example.from_dict(nlp.make_doc(text), annots))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d8949c",
   "metadata": {},
   "source": [
    "nlp.initialize(lambda: examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc401c",
   "metadata": {},
   "source": [
    "losses = {}\n",
    "for i in range(20):\n",
    "    random.shuffle(examples)\n",
    "    for batch in minibatch(examples, size=2):\n",
    "        nlp.update(batch,  drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,)\n",
    "        print(\"Losses\", losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tone-env",
   "language": "python",
   "name": "tone-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
